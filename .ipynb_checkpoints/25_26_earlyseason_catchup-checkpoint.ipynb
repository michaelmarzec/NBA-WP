{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2025-26 NBA Season Early Season Catchup\n",
    "This notebook processes missing game data from the start of the 2025-26 season.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from urllib.request import urlopen\n",
    "import urllib3\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_game_suffix(date, team1, team2):\n",
    "    \"\"\"Get the game suffix URL for a specific game\"\"\"\n",
    "    http = urllib3.PoolManager()\n",
    "    r = http.request(\"GET\", f'https://www.basketball-reference.com/boxscores/index.fcgi?year={date.year}&month={date.month}&day={date.day}')\n",
    "    suffix = None\n",
    "    if r.status==200:\n",
    "        soup = BeautifulSoup(r.data, 'html.parser')\n",
    "        for table in soup.find_all('table', attrs={'class': 'teams'}):\n",
    "            for anchor in table.find_all('a'):\n",
    "                if 'boxscores' in anchor.attrs['href']:\n",
    "                    if team1 in anchor.attrs['href'] or team2 in anchor.attrs['href']:\n",
    "                        suffix = anchor.attrs['href']\n",
    "    return suffix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pbp_helper(suffix):\n",
    "    \"\"\"Extract play-by-play data from basketball-reference\"\"\"\n",
    "    http = urllib3.PoolManager()\n",
    "    r = http.request(\"GET\", f'https://www.basketball-reference.com/boxscores/pbp{suffix}')\n",
    "    if r.status==200:\n",
    "        soup = BeautifulSoup(r.data, 'html.parser')\n",
    "        table = soup.find('table', attrs={'id': 'pbp'})\n",
    "        return pd.read_html(str(table), flavor='lxml')[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_df(df1):\n",
    "    \"\"\"Format the play-by-play dataframe\"\"\"\n",
    "    df1.columns = list(map(lambda x: x[1], list(df1.columns)))\n",
    "    t1 = list(df1.columns)[1].upper()\n",
    "    t2 = list(df1.columns)[5].upper()\n",
    "    q = 1\n",
    "    df = None\n",
    "    for index, row in df1.iterrows():\n",
    "        d = {'QUARTER': float('nan'), 'TIME_REMAINING': float('nan'), f'{t1}_ACTION': float('nan'), f'{t2}_ACTION': float('nan'), f'{t1}_SCORE': float('nan'), f'{t2}_SCORE': float('nan')}\n",
    "        if row['Time']=='2nd Q':\n",
    "            q = 2\n",
    "        elif row['Time']=='3rd Q':\n",
    "            q = 3\n",
    "        elif row['Time']=='4th Q':\n",
    "            q = 4\n",
    "        elif 'OT' in row['Time']:\n",
    "            q = row['Time'][0]+'OT'\n",
    "        try:\n",
    "            d['QUARTER'] = q\n",
    "            d['TIME_REMAINING'] = row['Time']\n",
    "            scores = row['Score'].split('-')\n",
    "            d[f'{t1}_SCORE'] = int(scores[0])\n",
    "            d[f'{t2}_SCORE'] = int(scores[1])\n",
    "            d[f'{t1}_ACTION'] = row[list(df1.columns)[1]]\n",
    "            d[f'{t2}_ACTION'] = row[list(df1.columns)[5]]\n",
    "            if df is None:\n",
    "                df = pd.DataFrame(columns = list(d.keys()))\n",
    "            df = pd.concat([df, pd.DataFrame(d, index=[0])], ignore_index=True)\n",
    "        except:\n",
    "            continue\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pbp(date, team1, team2):\n",
    "    \"\"\"Get play-by-play data for a specific game\"\"\"\n",
    "    date = pd.to_datetime(date)\n",
    "    suffix = get_game_suffix(date, team1, team2).replace('/boxscores', '')\n",
    "    df = get_pbp_helper(suffix)\n",
    "    df = df.iloc[1:].reset_index(drop=True)\n",
    "    df = format_df(df)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_game_wp(pbp_df, date, away_team, home_team):\n",
    "    \"\"\"Calculate winning time percentage for a game\"\"\"\n",
    "    pbp_df = pbp_df.rename(columns={\n",
    "        pbp_df.columns[4]:\"AWAY_SCORE\",\n",
    "        pbp_df.columns[5]:\"HOME_SCORE\"\n",
    "    })\n",
    "\n",
    "    pbp_df = pbp_df[['QUARTER','TIME_REMAINING','AWAY_SCORE','HOME_SCORE']]\n",
    "    pbp_df['TIME_REMAINING'] = pbp_df.TIME_REMAINING.replace('24:00.0','12:00.0')\n",
    "    pbp_df['TIME_REMAINING'] = pd.to_datetime(pbp_df['TIME_REMAINING'])\n",
    "    pbp_df['TIME_REMAINING'] = pd.to_datetime(pbp_df['TIME_REMAINING'],format= '%H:%M:%S').dt.time\n",
    "    pbp_df['AWAY_SCORE'] = pbp_df['AWAY_SCORE'].astype(int)\n",
    "    pbp_df['HOME_SCORE'] = pbp_df['HOME_SCORE'].astype(int)\n",
    "\n",
    "    quarter_beginning = '12:00:00'\n",
    "    quarter_ending = '00:00:00'\n",
    "    overtime_beginning = '05:00:00'\n",
    "\n",
    "    list_of_quarters = list(pbp_df['QUARTER'].unique())\n",
    "\n",
    "    full_df = pd.DataFrame()\n",
    "    for quarter in list_of_quarters:\n",
    "        quarter_df = pbp_df[pbp_df['QUARTER'] == quarter]\n",
    "\n",
    "        if quarter == 1:# add beginning of 1st quarter\n",
    "            quarter_df.loc[-1] = [1, quarter_beginning, 0, 0] \n",
    "            quarter_df.index = quarter_df.index + 1  \n",
    "            quarter_df = quarter_df.sort_index()\n",
    "\n",
    "            end_row = {\n",
    "                'QUARTER': [quarter],\n",
    "                'TIME_REMAINING': quarter_ending,\n",
    "                'AWAY_SCORE': [quarter_df.iloc[-1,2]],\n",
    "                'HOME_SCORE': [quarter_df.iloc[-1,3]]\n",
    "            }\n",
    "\n",
    "            end_row = pd.DataFrame(data=end_row)\n",
    "            quarter_df = pd.concat([quarter_df, end_row], axis=0).reset_index(drop=True)\n",
    "\n",
    "            temp_date = str(datetime.datetime.strptime('1900-01-01', '%Y-%m-%d').date())\n",
    "            quarter_df['TIME_REMAINING'] = pd.to_datetime(temp_date + \" \" + quarter_df.TIME_REMAINING.astype(str))\n",
    "            quarter_df['TIME_ELAPSED'] = (quarter_df['TIME_REMAINING'] - quarter_df['TIME_REMAINING'].shift(-1))\n",
    "            quarter_df['INDICATOR'] = np.where(\n",
    "                quarter_df['QUARTER'] == quarter_df['QUARTER'].shift(-1),\n",
    "                ((quarter_df['TIME_REMAINING'] - quarter_df['TIME_REMAINING'].shift(-1))/60000000000).view(int),\n",
    "                0\n",
    "            )\n",
    "\n",
    "            full_df = pd.concat([full_df, quarter_df], axis=0)\n",
    "\n",
    "\n",
    "        elif quarter in (2,3,4):\n",
    "            start_row = end_row\n",
    "            start_row['QUARTER'] = quarter\n",
    "            start_row['TIME_REMAINING'] = quarter_beginning\n",
    "\n",
    "            quarter_df = quarter_df.reset_index(drop=True)\n",
    "            quarter_df.index += 1\n",
    "\n",
    "            quarter_df = pd.concat([start_row, quarter_df],axis=0)\n",
    "            quarter_df = quarter_df.sort_index()\n",
    "\n",
    "            end_row = {\n",
    "                'QUARTER': [quarter],\n",
    "                'TIME_REMAINING': quarter_ending,\n",
    "                'AWAY_SCORE': [quarter_df.iloc[-1,2]],\n",
    "                'HOME_SCORE': [quarter_df.iloc[-1,3]]\n",
    "            }\n",
    "\n",
    "            end_row = pd.DataFrame(data=end_row)\n",
    "            quarter_df = pd.concat([quarter_df, end_row], axis=0).reset_index(drop=True)\n",
    "\n",
    "            temp_date = str(datetime.datetime.strptime('1900-01-01', '%Y-%m-%d').date())\n",
    "            quarter_df['TIME_REMAINING'] = pd.to_datetime(temp_date + \" \" + quarter_df.TIME_REMAINING.astype(str))\n",
    "            quarter_df['TIME_ELAPSED'] = (quarter_df['TIME_REMAINING'] - quarter_df['TIME_REMAINING'].shift(-1))\n",
    "            quarter_df['INDICATOR'] = np.where(\n",
    "                quarter_df['QUARTER'] == quarter_df['QUARTER'].shift(-1),\n",
    "                ((quarter_df['TIME_REMAINING'] - quarter_df['TIME_REMAINING'].shift(-1))/60000000000).view(int),\n",
    "                0\n",
    "            )\n",
    "\n",
    "            full_df = pd.concat([full_df, quarter_df], axis=0)\n",
    "\n",
    "        else:\n",
    "            start_row = end_row\n",
    "            start_row['QUARTER'] = quarter\n",
    "            start_row['TIME_REMAINING'] = overtime_beginning\n",
    "\n",
    "            quarter_df = quarter_df.reset_index(drop=True)\n",
    "            quarter_df.index += 1\n",
    "\n",
    "            quarter_df = pd.concat([start_row, quarter_df],axis=0)\n",
    "            quarter_df = quarter_df.sort_index()\n",
    "\n",
    "            end_row = {\n",
    "                'QUARTER': [quarter],\n",
    "                'TIME_REMAINING': quarter_ending,\n",
    "                'AWAY_SCORE': [quarter_df.iloc[-1,2]],\n",
    "                'HOME_SCORE': [quarter_df.iloc[-1,3]]\n",
    "            }\n",
    "\n",
    "            end_row = pd.DataFrame(data=end_row)\n",
    "            quarter_df = pd.concat([quarter_df, end_row], axis=0).reset_index(drop=True)\n",
    "\n",
    "            temp_date = str(datetime.datetime.strptime('1900-01-01', '%Y-%m-%d').date())\n",
    "            quarter_df['TIME_REMAINING'] = pd.to_datetime(temp_date + \" \" + quarter_df.TIME_REMAINING.astype(str))\n",
    "            quarter_df['TIME_ELAPSED'] = (quarter_df['TIME_REMAINING'] - quarter_df['TIME_REMAINING'].shift(-1))\n",
    "            quarter_df['INDICATOR'] = np.where(\n",
    "                quarter_df['QUARTER'] == quarter_df['QUARTER'].shift(-1),\n",
    "                ((quarter_df['TIME_REMAINING'] - quarter_df['TIME_REMAINING'].shift(-1))/60000000000).view(int),\n",
    "                0\n",
    "            )\n",
    "\n",
    "            full_df = pd.concat([full_df, quarter_df], axis=0)\n",
    "\n",
    "    full_df['LEADER'] = np.where(\n",
    "        full_df.HOME_SCORE > full_df.AWAY_SCORE,\n",
    "        'HOME_TEAM',\n",
    "        'AWAY_TEAM',\n",
    "    )\n",
    "\n",
    "    full_df['LEADER'] = np.where(\n",
    "        full_df.HOME_SCORE == full_df.AWAY_SCORE,\n",
    "        'NEITHER',\n",
    "        full_df.LEADER\n",
    "    )\n",
    "    full_df_gb = full_df.groupby('LEADER')['INDICATOR'].sum().reset_index() \n",
    "\n",
    "    teams = ['AWAY_TEAM','HOME_TEAM']\n",
    "    total_seconds = full_df_gb.INDICATOR.sum()\n",
    "\n",
    "    results_row = pd.DataFrame(columns=['DATE','AWAY_TEAM','HOME_TEAM','AWAY_WT','HOME_WT'],index=[0])\n",
    "    results_row['DATE'] = date\n",
    "    results_row['AWAY_TEAM'] = away_team\n",
    "    results_row['HOME_TEAM'] = home_team\n",
    "    \n",
    "    try:\n",
    "        away_seconds_leading = full_df_gb[full_df_gb.LEADER == 'AWAY_TEAM'].INDICATOR.values[0]\n",
    "    except:\n",
    "        away_seconds_leading = 0\n",
    "    away_wp = away_seconds_leading / total_seconds\n",
    "\n",
    "    try:\n",
    "        home_seconds_leading = full_df_gb[full_df_gb.LEADER == 'HOME_TEAM'].INDICATOR.values[0]\n",
    "    except:\n",
    "        home_seconds_leading = 0\n",
    "    home_wp = home_seconds_leading / total_seconds\n",
    "    \n",
    "    results_row['AWAY_WT'] = away_wp\n",
    "    results_row['HOME_WT'] = home_wp\n",
    "\n",
    "    return results_row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tm_avg_metric(df, metric):\n",
    "    \"\"\"Calculate team average for each metric\"\"\"\n",
    "    # set metric columns\n",
    "    if metric in ('WT','LT'):\n",
    "        away_col = 'AWAY_' + metric\n",
    "        home_col = 'HOME_' + metric\n",
    "    elif metric == 'TIE_PC':\n",
    "        away_col = metric\n",
    "        home_col = metric\n",
    "    \n",
    "    # reformat into single column\n",
    "    nba_results_away = df[['DATE','AWAY_TEAM', away_col]].rename(columns={'AWAY_TEAM':'TEAM',away_col:metric})\n",
    "    nba_results_home = df[['DATE','HOME_TEAM', home_col]].rename(columns={'HOME_TEAM':'TEAM',home_col:metric})\n",
    "    \n",
    "    # concatenate\n",
    "    nba_results_reformat = pd.concat([nba_results_away, nba_results_home]).reset_index(drop=True)\n",
    "    \n",
    "    # find team averages\n",
    "    nba_results_agg = nba_results_reformat.groupby(['TEAM']).mean().reset_index()\n",
    "    return nba_results_agg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Existing Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total games in file: 1216 games\n",
      "\n",
      "Date range: 2025-10-21 00:00:00 to 2026-04-12 00:00:00\n",
      "\n",
      "Column names: ['DATE', 'AWAY_TEAM', 'HOME_TEAM', 'AWAY_WT', 'HOME_WT']\n",
      "\n",
      "First few rows:\n",
      "        DATE AWAY_TEAM HOME_TEAM  AWAY_WT  HOME_WT\n",
      "0 2025-10-21       HOU       OKC      NaN      NaN\n",
      "1 2025-10-21       GSW       LAL      NaN      NaN\n",
      "2 2025-10-22       BRK       CHO      NaN      NaN\n",
      "3 2025-10-22       CLE       NYK      NaN      NaN\n",
      "4 2025-10-22       MIA       ORL      NaN      NaN\n"
     ]
    }
   ],
   "source": [
    "# Read existing files\n",
    "nba_wt_results_df = pd.read_csv('25_26_earlyseason_catchup/25_26_wt_results.csv')\n",
    "nba_wt_results_df['DATE'] = pd.to_datetime(nba_wt_results_df['DATE'])\n",
    "\n",
    "print(f\"Total games in file: {len(nba_wt_results_df)} games\")\n",
    "print(f\"\\nDate range: {nba_wt_results_df['DATE'].min()} to {nba_wt_results_df['DATE'].max()}\")\n",
    "print(f\"\\nColumn names: {list(nba_wt_results_df.columns)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(nba_wt_results_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Games with Missing Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Games with missing WT data: 58\n",
      "Date range: 2025-10-21 00:00:00 to 2025-10-28 00:00:00\n",
      "\n",
      "First few games with missing data:\n",
      "        DATE AWAY_TEAM HOME_TEAM  AWAY_WT  HOME_WT\n",
      "0 2025-10-21       HOU       OKC      NaN      NaN\n",
      "1 2025-10-21       GSW       LAL      NaN      NaN\n",
      "2 2025-10-22       BRK       CHO      NaN      NaN\n",
      "3 2025-10-22       CLE       NYK      NaN      NaN\n",
      "4 2025-10-22       MIA       ORL      NaN      NaN\n",
      "5 2025-10-22       PHI       BOS      NaN      NaN\n",
      "6 2025-10-22       TOR       ATL      NaN      NaN\n",
      "7 2025-10-22       DET       CHI      NaN      NaN\n",
      "8 2025-10-22       NOP       MEM      NaN      NaN\n",
      "9 2025-10-22       WAS       MIL      NaN      NaN\n"
     ]
    }
   ],
   "source": [
    "# Find games where AWAY_WT or HOME_WT are null/empty\n",
    "# Only look at games before today\n",
    "today = pd.Timestamp.today().normalize()\n",
    "\n",
    "# Filter for games before today with missing WT data\n",
    "missing_data_games = nba_wt_results_df[\n",
    "    (nba_wt_results_df['DATE'] < today) & \n",
    "    (nba_wt_results_df['AWAY_WT'].isna() | nba_wt_results_df['HOME_WT'].isna())\n",
    "].copy()\n",
    "\n",
    "print(f\"\\nGames with missing WT data: {len(missing_data_games)}\")\n",
    "if len(missing_data_games) > 0:\n",
    "    print(f\"Date range: {missing_data_games['DATE'].min()} to {missing_data_games['DATE'].max()}\")\n",
    "    print(f\"\\nFirst few games with missing data:\")\n",
    "    print(missing_data_games[['DATE', 'AWAY_TEAM', 'HOME_TEAM', 'AWAY_WT', 'HOME_WT']].head(10))\n",
    "else:\n",
    "    print(\"No missing data found!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Games with Missing Data\n",
    "**Note:** This will scrape basketball-reference.com for each game with missing data. \n",
    "- Includes automatic rate limiting (sleeps every 9 games for 2 minutes)\n",
    "- Progress is tracked for each game\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to process 58 games with missing data...\n",
      "\n",
      "[1/58] Processing: 2025-10-21 - HOU @ OKC\n"
     ]
    }
   ],
   "source": [
    "# Sort games by date to process chronologically\n",
    "missing_data_games_sorted = missing_data_games.sort_values('DATE').reset_index(drop=True)\n",
    "\n",
    "# Dictionary to store updated data\n",
    "updated_games = {}\n",
    "failed_games = []\n",
    "\n",
    "print(f\"Starting to process {len(missing_data_games_sorted)} games with missing data...\\n\")\n",
    "\n",
    "for idx in range(len(missing_data_games_sorted)):\n",
    "    # Rate limiting: sleep every 9 games\n",
    "    if (idx % 5) == 0 and idx > 0:\n",
    "        print(f\"\\n[Rate limiting] Sleeping for 120 seconds...\\n\")\n",
    "        sleep(120)\n",
    "    \n",
    "    date = missing_data_games_sorted.loc[idx, \"DATE\"]\n",
    "    away_team = missing_data_games_sorted.loc[idx, \"AWAY_TEAM\"]\n",
    "    home_team = missing_data_games_sorted.loc[idx, \"HOME_TEAM\"]\n",
    "    \n",
    "    try:\n",
    "        print(f\"[{idx+1}/{len(missing_data_games_sorted)}] Processing: {date.strftime('%Y-%m-%d')} - {away_team} @ {home_team}\")\n",
    "        \n",
    "        pbp_df = get_pbp(date, away_team, home_team)\n",
    "        wp_results = calculate_game_wp(pbp_df, date, away_team, home_team)\n",
    "        \n",
    "        # Store the results\n",
    "        game_key = (pd.Timestamp(date), away_team, home_team)\n",
    "        updated_games[game_key] = {\n",
    "            'AWAY_WT': wp_results['AWAY_WT'].values[0],\n",
    "            'HOME_WT': wp_results['HOME_WT'].values[0]\n",
    "        }\n",
    "        \n",
    "        print(f\"  ✓ Success - WT: Away={wp_results['AWAY_WT'].values[0]:.3f}, Home={wp_results['HOME_WT'].values[0]:.3f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Failed: {str(e)}\")\n",
    "        failed_games.append({\n",
    "            'DATE': date,\n",
    "            'AWAY_TEAM': away_team,\n",
    "            'HOME_TEAM': home_team,\n",
    "            'ERROR': str(e)\n",
    "        })\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Processing complete!\")\n",
    "print(f\"Successfully processed: {len(updated_games)} games\")\n",
    "print(f\"Failed: {len(failed_games)} games\")\n",
    "\n",
    "if len(failed_games) > 0:\n",
    "    print(f\"\\nFailed games:\")\n",
    "    failed_df = pd.DataFrame(failed_games)\n",
    "    print(failed_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Original DataFrame with New Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the original dataframe with the new WT values\n",
    "for game_key, wt_values in updated_games.items():\n",
    "    date, away_team, home_team = game_key\n",
    "    mask = (nba_wt_results_df['DATE'] == date) & \\\n",
    "           (nba_wt_results_df['AWAY_TEAM'] == away_team) & \\\n",
    "           (nba_wt_results_df['HOME_TEAM'] == home_team)\n",
    "    \n",
    "    nba_wt_results_df.loc[mask, 'AWAY_WT'] = wt_values['AWAY_WT']\n",
    "    nba_wt_results_df.loc[mask, 'HOME_WT'] = wt_values['HOME_WT']\n",
    "\n",
    "# Save updated results\n",
    "nba_wt_results_df.to_csv('25_26_earlyseason_catchup/25_26_wt_results_updated.csv', index=False)\n",
    "\n",
    "print(f\"Updated results saved!\")\n",
    "print(f\"Total games in file: {len(nba_wt_results_df)}\")\n",
    "print(f\"Games with data: {nba_wt_results_df['AWAY_WT'].notna().sum()}\")\n",
    "print(f\"Games still missing data: {nba_wt_results_df['AWAY_WT'].isna().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Aggregated Results with Cleaning The Glass Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only use games that have WT data for aggregation\n",
    "nba_wt_results_complete = nba_wt_results_df[nba_wt_results_df['AWAY_WT'].notna()].copy()\n",
    "\n",
    "# Calculate LT% and TIE%\n",
    "nba_wt_results_complete['AWAY_LT'] = nba_wt_results_complete['HOME_WT']\n",
    "nba_wt_results_complete['HOME_LT'] = nba_wt_results_complete['AWAY_WT']\n",
    "nba_wt_results_complete['TIE_PC'] = 1 - (nba_wt_results_complete['AWAY_WT'] + nba_wt_results_complete['HOME_WT'])\n",
    "\n",
    "# Create dataset of wt/lt/tie%\n",
    "wt_results = calculate_tm_avg_metric(nba_wt_results_complete, 'WT')\n",
    "lt_results = calculate_tm_avg_metric(nba_wt_results_complete, 'LT')\n",
    "tie_results = calculate_tm_avg_metric(nba_wt_results_complete, 'TIE_PC')\n",
    "\n",
    "del wt_results['DATE']\n",
    "del lt_results['DATE']\n",
    "del tie_results['DATE']\n",
    "\n",
    "nba_results_agg = pd.merge(wt_results, lt_results, how='inner', on='TEAM')\n",
    "nba_results_agg = pd.merge(nba_results_agg, tie_results, how='inner', on='TEAM')\n",
    "\n",
    "print(\"Calculated WT, LT, and TIE metrics for all teams\")\n",
    "print(f\"\\nTeams in aggregation: {len(nba_results_agg)}\")\n",
    "print(f\"Based on {len(nba_wt_results_complete)} completed games\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape Cleaning The Glass data\n",
    "print(\"Scraping Cleaning The Glass for current standings...\")\n",
    "\n",
    "html = urlopen('https://cleaningtheglass.com/stats/league/summary')\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "table = soup.find(\"table\")\n",
    "df_ctg = pd.read_html(str(table), flavor=\"lxml\")[0]\n",
    "df_ctg.columns = df_ctg.columns.get_level_values(1)\n",
    "df_ctg = df_ctg.iloc[: , 1:]\n",
    "df_ctg = df_ctg.iloc[: , :7]\n",
    "df_ctg_1 = df_ctg['Team']\n",
    "df_ctg_2 = df_ctg.iloc[: , 2:5]\n",
    "df_ctg_3 = df_ctg.iloc[: , 5:]\n",
    "df_ctg = pd.concat([df_ctg_1, df_ctg_2, df_ctg_3], axis=1)\n",
    "\n",
    "# Team name mapping\n",
    "team_names = {\n",
    "    'full_name':[\n",
    "        'Atlanta',\n",
    "        'Boston',\n",
    "        'Brooklyn',\n",
    "        'Charlotte',\n",
    "        'Chicago',\n",
    "        'Cleveland',\n",
    "        'Dallas',\n",
    "        'Denver',\n",
    "        'Detroit',\n",
    "        'Golden State',\n",
    "        'Houston',\n",
    "        'Indiana',\n",
    "        'LA Clippers',\n",
    "        'LA Lakers',\n",
    "        'Memphis',\n",
    "        'Miami',\n",
    "        'Milwaukee',\n",
    "        'Minnesota',\n",
    "        'New Orleans',\n",
    "        'New York',\n",
    "        'Oklahoma City',\n",
    "        'Orlando',\n",
    "        'Philadelphia',\n",
    "        'Phoenix',\n",
    "        'Portland',\n",
    "        'Sacramento',\n",
    "        'San Antonio',\n",
    "        'Toronto',\n",
    "        'Utah',\n",
    "        'Washington'\n",
    "    ],\n",
    "    'abbr_name':[\n",
    "        'ATL',\n",
    "        'BOS',\n",
    "        'BRK',\n",
    "        'CHO',\n",
    "        'CHI',\n",
    "        'CLE',\n",
    "        'DAL',\n",
    "        'DEN',\n",
    "        'DET',\n",
    "        'GSW',\n",
    "        'HOU',\n",
    "        'IND',\n",
    "        'LAC',\n",
    "        'LAL',\n",
    "        'MEM',\n",
    "        'MIA',\n",
    "        'MIL',\n",
    "        'MIN',\n",
    "        'NOP',\n",
    "        'NYK',\n",
    "        'OKC',\n",
    "        'ORL',\n",
    "        'PHI',\n",
    "        'PHO',\n",
    "        'POR',\n",
    "        'SAC',\n",
    "        'SAS',\n",
    "        'TOR',\n",
    "        'UTA',\n",
    "        'WAS'\n",
    "    ]\n",
    "}\n",
    "\n",
    "team_name_map = pd.DataFrame(team_names)\n",
    "\n",
    "df_ctg = pd.merge(df_ctg, team_name_map, how='inner', left_on='Team', right_on='full_name')\n",
    "del df_ctg['Team']\n",
    "del df_ctg['full_name']\n",
    "df_ctg = df_ctg.rename(columns={\n",
    "    'abbr_name':'TEAM',\n",
    "    'Win%':'WP',\n",
    "    'Exp W82':'EXPECTED_WIN',\n",
    "    'Point Diff':'PT_DIFF',\n",
    "    'W':'Wins',\n",
    "    'L':'Losses'\n",
    "})\n",
    "\n",
    "df_ctg['WP'] = df_ctg['WP'].str.rstrip('%').astype('float') / 100.0\n",
    "df_ctg['EXPECTED_WP'] = df_ctg['EXPECTED_WIN'] / 82\n",
    "\n",
    "print(\"Successfully scraped Cleaning The Glass data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge everything together\n",
    "nba_wt_results_agg = pd.merge(nba_results_agg, df_ctg, how='inner', on='TEAM')\n",
    "nba_wt_results_agg['WT_v_WP'] = nba_wt_results_agg['WT'] - nba_wt_results_agg['WP']\n",
    "nba_wt_results_agg['WT_v_EXP_WP'] = nba_wt_results_agg['WT'] - nba_wt_results_agg['EXPECTED_WP']\n",
    "\n",
    "# Save aggregated results\n",
    "nba_wt_results_agg.to_csv('25_26_earlyseason_catchup/nba_wt_results_agg_updated.csv', index=False)\n",
    "\n",
    "print(\"Aggregated results saved!\")\n",
    "print(f\"\\nFinal dataset includes {len(nba_wt_results_agg)} teams\")\n",
    "print(\"\\nPreview:\")\n",
    "nba_wt_results_agg.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that WT + LT + TIE = 1 for all teams\n",
    "total_check = nba_wt_results_agg['WT'] + nba_wt_results_agg['LT'] + nba_wt_results_agg['TIE_PC']\n",
    "\n",
    "print(\"Validation: WT + LT + TIE should equal 1.0\")\n",
    "print(f\"Min: {total_check.min():.6f}\")\n",
    "print(f\"Max: {total_check.max():.6f}\")\n",
    "print(f\"\\nAll values valid: {total_check.between(0.999, 1.001).all()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"CATCHUP COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nFiles updated in: 25_26_earlyseason_catchup/\")\n",
    "print(f\"  - 25_26_wt_results.csv (game-by-game results)\")\n",
    "print(f\"  - nba_wt_results_agg.csv (team aggregations)\")\n",
    "print(f\"\\nTotal games in file: {len(nba_wt_results_df)}\")\n",
    "print(f\"Games processed/updated: {len(updated_games)}\")\n",
    "print(f\"Failed games: {len(failed_games)}\")\n",
    "print(f\"\\nYou can now use these files with your Lambda function!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
