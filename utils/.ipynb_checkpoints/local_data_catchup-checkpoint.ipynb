{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49ce4804-8a57-46ac-96d3-365e32861407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from requests import get\n",
    "from time import sleep\n",
    "from urllib.request import urlopen\n",
    "import urllib3\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa941bbc-0045-4451-a6bc-1f86fb9a5aaf",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9847261-7fd4-4230-bf4a-b74e14e7f3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_game_suffix(date, team1, team2):\n",
    "\t# r = get(f'https://www.basketball-reference.com/boxscores/index.fcgi?year={date.year}&month={date.month}&day={date.day}')\n",
    "\t# suffix = None\n",
    "\t# if r.status_code==200:\n",
    "\t#     soup = BeautifulSoup(r.content, 'html.parser')\n",
    "\t#     for table in soup.find_all('table', attrs={'class': 'teams'}):\n",
    "\t#         for anchor in table.find_all('a'):\n",
    "\t#             if 'boxscores' in anchor.attrs['href']:\n",
    "\t#                 if team1 in anchor.attrs['href'] or team2 in anchor.attrs['href']:\n",
    "\t#                     suffix = anchor.attrs['href']\n",
    "\t# return suffix\n",
    "\thttp = urllib3.PoolManager()\n",
    "\tr = http.request(\"GET\", f'https://www.basketball-reference.com/boxscores/index.fcgi?year={date.year}&month={date.month}&day={date.day}')\n",
    "\tsuffix = None\n",
    "\tif r.status==200:\n",
    "\t\tsoup = BeautifulSoup(r.data, 'html.parser')\n",
    "\t\tfor table in soup.find_all('table', attrs={'class': 'teams'}):\n",
    "\t\t\tfor anchor in table.find_all('a'):\n",
    "\t\t\t\tif 'boxscores' in anchor.attrs['href']:\n",
    "\t\t\t\t\tif team1 in anchor.attrs['href'] or team2 in anchor.attrs['href']:\n",
    "\t\t\t\t\t\tsuffix = anchor.attrs['href']\n",
    "\treturn suffix\n",
    "# Extract game log (modified version for updates to the basketball_reference_scraper library)\n",
    "def get_pbp_helper(suffix):\n",
    "\tselector = f'#pbp'\n",
    "\t# r = get(f'https://www.basketball-reference.com/boxscores/pbp{suffix}')\n",
    "\t# if r.status_code==200:\n",
    "\t#     soup = BeautifulSoup(r.content, 'html.parser')\n",
    "\t#     table = soup.find('table', attrs={'id': 'pbp'})\n",
    "\t#     return pd.read_html(str(table), flavor='bs4')[0]\n",
    "\thttp = urllib3.PoolManager()\n",
    "\tr =  http.request(\"GET\",f'https://www.basketball-reference.com/boxscores/pbp{suffix}')\n",
    "\tif r.status==200:\n",
    "\t\tsoup = BeautifulSoup(r.data, 'html.parser')\n",
    "\t\ttable = soup.find('table', attrs={'id': 'pbp'})\n",
    "\t\treturn pd.read_html(str(table), flavor='lxml')[0]\n",
    "\n",
    "def format_df(df1):\n",
    "\tdf1.columns = list(map(lambda x: x[1], list(df1.columns)))\n",
    "\tt1 = list(df1.columns)[1].upper()\n",
    "\tt2 = list(df1.columns)[5].upper()\n",
    "\tq = 1\n",
    "\tdf = None\n",
    "\tfor index, row in df1.iterrows():\n",
    "\t\td = {'QUARTER': float('nan'), 'TIME_REMAINING': float('nan'), f'{t1}_ACTION': float('nan'), f'{t2}_ACTION': float('nan'), f'{t1}_SCORE': float('nan'), f'{t2}_SCORE': float('nan')}\n",
    "\t\tif row['Time']=='2nd Q':\n",
    "\t\t\tq = 2\n",
    "\t\telif row['Time']=='3rd Q':\n",
    "\t\t\tq = 3\n",
    "\t\telif row['Time']=='4th Q':\n",
    "\t\t\tq = 4\n",
    "\t\telif 'OT' in row['Time']:\n",
    "\t\t\tq = row['Time'][0]+'OT'\n",
    "\t\ttry:\n",
    "\t\t\td['QUARTER'] = q\n",
    "\t\t\td['TIME_REMAINING'] = row['Time']\n",
    "\t\t\tscores = row['Score'].split('-')\n",
    "\t\t\td[f'{t1}_SCORE'] = int(scores[0])\n",
    "\t\t\td[f'{t2}_SCORE'] = int(scores[1])\n",
    "\t\t\td[f'{t1}_ACTION'] = row[list(df1.columns)[1]]\n",
    "\t\t\td[f'{t2}_ACTION'] = row[list(df1.columns)[5]]\n",
    "\t\t\tif df is None:\n",
    "\t\t\t\tdf = pd.DataFrame(columns = list(d.keys()))\n",
    "\t\t\tdf = pd.concat([df, pd.DataFrame(d, index=[0])], ignore_index=True)#df.append(d, ignore_index=True)\n",
    "\t\texcept:\n",
    "\t\t\tcontinue\n",
    "\treturn df\n",
    "\n",
    "def get_pbp(date, team1, team2):\n",
    "\tdate = pd.to_datetime(date)\n",
    "\tsuffix = get_game_suffix(date, team1, team2).replace('/boxscores', '')\n",
    "\tdf = get_pbp_helper(suffix)\n",
    "\tdf = df.iloc[1:].reset_index(drop=True)\n",
    "\tdf = format_df(df)\n",
    "\treturn df\n",
    "\n",
    "# calculate winning time %\n",
    "def calculate_game_wp(pbp_df, date, away_team, home_team):\n",
    "\tpbp_df = pbp_df.rename(columns={\n",
    "\t\tpbp_df.columns[4]:\"AWAY_SCORE\",\n",
    "\t\tpbp_df.columns[5]:\"HOME_SCORE\"\n",
    "\t})\n",
    "\n",
    "\tpbp_df = pbp_df[['QUARTER','TIME_REMAINING','AWAY_SCORE','HOME_SCORE']]\n",
    "\tpbp_df['TIME_REMAINING'] = pbp_df.TIME_REMAINING.replace('24:00.0','12:00.0')\n",
    "\tpbp_df['TIME_REMAINING'] = pd.to_datetime(pbp_df['TIME_REMAINING'])\n",
    "\tpbp_df['TIME_REMAINING'] = pd.to_datetime(pbp_df['TIME_REMAINING'],format= '%H:%M:%S').dt.time\n",
    "\tpbp_df['AWAY_SCORE'] = pbp_df['AWAY_SCORE'].astype(int)\n",
    "\tpbp_df['HOME_SCORE'] = pbp_df['HOME_SCORE'].astype(int)\n",
    "\n",
    "\tquarter_beginning = '12:00:00'\n",
    "\tquarter_ending = '00:00:00'\n",
    "\tovertime_beginning = '05:00:00'\n",
    "\n",
    "\tlist_of_quarters = list(pbp_df['QUARTER'].unique())\n",
    "\n",
    "\tfull_df = pd.DataFrame()\n",
    "\tfor quarter in list_of_quarters:\n",
    "\t\tquarter_df = pbp_df[pbp_df['QUARTER'] == quarter]\n",
    "\n",
    "\t\tif quarter == 1:# add beginning of 1st quarter\n",
    "\t\t\tquarter_df.loc[-1] = [1, quarter_beginning, 0, 0] \n",
    "\t\t\tquarter_df.index = quarter_df.index + 1  \n",
    "\t\t\tquarter_df = quarter_df.sort_index()\n",
    "\n",
    "\t\t\tend_row = {\n",
    "\t\t\t\t'QUARTER': [quarter],\n",
    "\t\t\t\t'TIME_REMAINING': quarter_ending,\n",
    "\t\t\t\t'AWAY_SCORE': [quarter_df.iloc[-1,2]],\n",
    "\t\t\t\t'HOME_SCORE': [quarter_df.iloc[-1,3]]\n",
    "\t\t\t}\n",
    "\n",
    "\t\t\tend_row = pd.DataFrame(data=end_row)\n",
    "\t\t\tquarter_df = pd.concat([quarter_df, end_row], axis=0).reset_index(drop=True)\n",
    "\n",
    "\t\t\ttemp_date = str(datetime.datetime.strptime('1900-01-01', '%Y-%m-%d').date())\n",
    "\t\t\tquarter_df['TIME_REMAINING'] = pd.to_datetime(temp_date + \" \" + quarter_df.TIME_REMAINING.astype(str))\n",
    "\t\t\tquarter_df['TIME_ELAPSED'] = (quarter_df['TIME_REMAINING'] - quarter_df['TIME_REMAINING'].shift(-1))\n",
    "\t\t\tquarter_df['INDICATOR'] = np.where(\n",
    "\t\t\t\tquarter_df['QUARTER'] == quarter_df['QUARTER'].shift(-1),\n",
    "\t\t\t\t((quarter_df['TIME_REMAINING'] - quarter_df['TIME_REMAINING'].shift(-1))/60000000000).view(int),\n",
    "\t\t\t\t0\n",
    "\t\t\t)\n",
    "\n",
    "\t\t\tfull_df = pd.concat([full_df, quarter_df], axis=0)\n",
    "\n",
    "\n",
    "\t\telif quarter in (2,3,4):\n",
    "\t\t\tstart_row = end_row\n",
    "\t\t\tstart_row['QUARTER'] = quarter\n",
    "\t\t\tstart_row['TIME_REMAINING'] = quarter_beginning\n",
    "\n",
    "\t\t\tquarter_df = quarter_df.reset_index(drop=True)\n",
    "\t\t\tquarter_df.index += 1\n",
    "\n",
    "\t\t\tquarter_df = pd.concat([start_row, quarter_df],axis=0)\n",
    "\t\t\tquarter_df = quarter_df.sort_index()\n",
    "\n",
    "\t\t\tend_row = {\n",
    "\t\t\t\t'QUARTER': [quarter],\n",
    "\t\t\t\t'TIME_REMAINING': quarter_ending,\n",
    "\t\t\t\t'AWAY_SCORE': [quarter_df.iloc[-1,2]],\n",
    "\t\t\t\t'HOME_SCORE': [quarter_df.iloc[-1,3]]\n",
    "\t\t\t}\n",
    "\n",
    "\t\t\tend_row = pd.DataFrame(data=end_row)\n",
    "\t\t\tquarter_df = pd.concat([quarter_df, end_row], axis=0).reset_index(drop=True)\n",
    "\n",
    "\t\t\ttemp_date = str(datetime.datetime.strptime('1900-01-01', '%Y-%m-%d').date())\n",
    "\t\t\tquarter_df['TIME_REMAINING'] = pd.to_datetime(temp_date + \" \" + quarter_df.TIME_REMAINING.astype(str))\n",
    "\t\t\tquarter_df['TIME_ELAPSED'] = (quarter_df['TIME_REMAINING'] - quarter_df['TIME_REMAINING'].shift(-1))\n",
    "\t\t\tquarter_df['INDICATOR'] = np.where(\n",
    "\t\t\t\tquarter_df['QUARTER'] == quarter_df['QUARTER'].shift(-1),\n",
    "\t\t\t\t((quarter_df['TIME_REMAINING'] - quarter_df['TIME_REMAINING'].shift(-1))/60000000000).view(int),\n",
    "\t\t\t\t0\n",
    "\t\t\t)\n",
    "\n",
    "\t\t\tfull_df = pd.concat([full_df, quarter_df], axis=0)\n",
    "\n",
    "\t\telse:\n",
    "\t\t\tstart_row = end_row\n",
    "\t\t\tstart_row['QUARTER'] = quarter\n",
    "\t\t\tstart_row['TIME_REMAINING'] = overtime_beginning\n",
    "\n",
    "\t\t\tquarter_df = quarter_df.reset_index(drop=True)\n",
    "\t\t\tquarter_df.index += 1\n",
    "\n",
    "\t\t\tquarter_df = pd.concat([start_row, quarter_df],axis=0)\n",
    "\t\t\tquarter_df = quarter_df.sort_index()\n",
    "\n",
    "\t\t\tend_row = {\n",
    "\t\t\t\t'QUARTER': [quarter],\n",
    "\t\t\t\t'TIME_REMAINING': quarter_ending,\n",
    "\t\t\t\t'AWAY_SCORE': [quarter_df.iloc[-1,2]],\n",
    "\t\t\t\t'HOME_SCORE': [quarter_df.iloc[-1,3]]\n",
    "\t\t\t}\n",
    "\n",
    "\t\t\tend_row = pd.DataFrame(data=end_row)\n",
    "\t\t\tquarter_df = pd.concat([quarter_df, end_row], axis=0).reset_index(drop=True)\n",
    "\n",
    "\t\t\ttemp_date = str(datetime.datetime.strptime('1900-01-01', '%Y-%m-%d').date())\n",
    "\t\t\tquarter_df['TIME_REMAINING'] = pd.to_datetime(temp_date + \" \" + quarter_df.TIME_REMAINING.astype(str))\n",
    "\t\t\tquarter_df['TIME_ELAPSED'] = (quarter_df['TIME_REMAINING'] - quarter_df['TIME_REMAINING'].shift(-1))\n",
    "\t\t\tquarter_df['INDICATOR'] = np.where(\n",
    "\t\t\t\tquarter_df['QUARTER'] == quarter_df['QUARTER'].shift(-1),\n",
    "\t\t\t\t((quarter_df['TIME_REMAINING'] - quarter_df['TIME_REMAINING'].shift(-1))/60000000000).view(int),\n",
    "\t\t\t\t0\n",
    "\t\t\t)\n",
    "\n",
    "\t\t\tfull_df = pd.concat([full_df, quarter_df], axis=0)\n",
    "\n",
    "\tfull_df['LEADER'] = np.where(\n",
    "\t\tfull_df.HOME_SCORE > full_df.AWAY_SCORE,\n",
    "\t\t'HOME_TEAM',\n",
    "\t\t'AWAY_TEAM',\n",
    "\t)\n",
    "\n",
    "\tfull_df['LEADER'] = np.where(\n",
    "\t\tfull_df.HOME_SCORE == full_df.AWAY_SCORE,\n",
    "\t\t'NEITHER',\n",
    "\t\tfull_df.LEADER\n",
    "\t)\n",
    "\tfull_df_gb = full_df.groupby('LEADER')['INDICATOR'].sum().reset_index() \n",
    "\n",
    "\tteams = ['AWAY_TEAM','HOME_TEAM']\n",
    "\ttotal_seconds = full_df_gb.INDICATOR.sum()\n",
    "\n",
    "\tresults_row = pd.DataFrame(columns=['DATE','AWAY_TEAM','HOME_TEAM','AWAY_WT','HOME_WT'],index=[0])\n",
    "\tresults_row['DATE'] = date\n",
    "\tresults_row['AWAY_TEAM'] = away_team\n",
    "\tresults_row['HOME_TEAM'] = home_team\n",
    "\t\n",
    "\ttry:\n",
    "\t\taway_seconds_leading = full_df_gb[full_df_gb.LEADER == 'AWAY_TEAM'].INDICATOR.values[0]\n",
    "\texcept:\n",
    "\t\taway_seconds_leading = 0\n",
    "\taway_wp = away_seconds_leading / total_seconds\n",
    "\n",
    "\ttry:\n",
    "\t\thome_seconds_leading = full_df_gb[full_df_gb.LEADER == 'HOME_TEAM'].INDICATOR.values[0]\n",
    "\texcept:\n",
    "\t\thome_seconds_leading = 0\n",
    "\thome_wp = home_seconds_leading / total_seconds\n",
    "\t\n",
    "\tresults_row['AWAY_WT'] = away_wp\n",
    "\tresults_row['HOME_WT'] = home_wp\n",
    "\n",
    "\treturn results_row\n",
    "\n",
    "\t\n",
    "# function to calculate team average for each metric\n",
    "def calculate_tm_avg_metric(df, metric):\n",
    "\t# set metric columns\n",
    "\tif metric in ('WT','LT'):\n",
    "\t\taway_col = 'AWAY_' + metric\n",
    "\t\thome_col = 'HOME_' + metric\n",
    "\telif metric == 'TIE_PC':\n",
    "\t\taway_col = metric\n",
    "\t\thome_col = metric\n",
    "\t\n",
    "\t# reformat into single column\n",
    "\tnba_results_22_23_away = df[['DATE','AWAY_TEAM', away_col]].rename(columns={'AWAY_TEAM':'TEAM',away_col:metric})\n",
    "\tnba_results_22_23_home = df[['DATE','HOME_TEAM', home_col]].rename(columns={'HOME_TEAM':'TEAM',home_col:metric})\n",
    "\t\t\n",
    "\t\t\n",
    "\n",
    "\t# concatenate\n",
    "\tnba_results_22_23_reformat = pd.concat([nba_results_22_23_away, nba_results_22_23_home]).reset_index(drop=True)\n",
    "\t\n",
    "\t# find team averages\n",
    "\tnba_results_22_23_agg = nba_results_22_23_reformat.groupby(['TEAM']).mean().reset_index()\n",
    "\treturn nba_results_22_23_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e208d5ec-d792-4951-b47c-97d96fe2e1e8",
   "metadata": {},
   "source": [
    "## Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9f7feb6-9dcb-4b4c-8df1-d1a2c5ba9582",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/99/vl9z3jvj5tl3139_1l7_rpbw0000gp/T/ipykernel_99393/1381035465.py:3: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  nba_schedule_df['DATE'] = pd.to_datetime(nba_schedule_df['DATE'])\n",
      "/var/folders/99/vl9z3jvj5tl3139_1l7_rpbw0000gp/T/ipykernel_99393/1381035465.py:6: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  nba_wt_results_df['DATE'] = pd.to_datetime(nba_wt_results_df['DATE'])\n"
     ]
    }
   ],
   "source": [
    "# read CSVs\n",
    "nba_schedule_df = pd.read_csv('24_25_catchup/24_25_nba_schedule.csv')\n",
    "nba_schedule_df['DATE'] = pd.to_datetime(nba_schedule_df['DATE'])\n",
    "\n",
    "nba_wt_results_df = pd.read_csv('24_25_catchup/24_25_wt_results.csv')\n",
    "nba_wt_results_df['DATE'] = pd.to_datetime(nba_wt_results_df['DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ddd9002-03c2-4148-a547-2005a742b7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce to retro dates?\n",
    "nba_schedule_df_retro = nba_schedule_df[\n",
    "    (nba_schedule_df.DATE>='2024-11-9') &\n",
    "    (nba_schedule_df.DATE<='2024-11-9')\n",
    "].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05d2ecdf-9f8b-4f8a-b789-15a51a1ddfc8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "lxml not found, please install it",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m away_team \u001b[38;5;241m=\u001b[39m nba_schedule_df_retro\u001b[38;5;241m.\u001b[39mloc[game_number, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAWAY_TEAM\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      9\u001b[0m home_team \u001b[38;5;241m=\u001b[39m nba_schedule_df_retro\u001b[38;5;241m.\u001b[39mloc[game_number, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHOME_TEAM\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 10\u001b[0m pbp_df \u001b[38;5;241m=\u001b[39m \u001b[43mget_pbp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maway_team\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhome_team\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# print(str(date) + '-' + str(game_number) + '-' + away_team + '-' + home_team)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m wp_results \u001b[38;5;241m=\u001b[39m calculate_game_wp(pbp_df, date, away_team, home_team)\n",
      "Cell \u001b[0;32mIn[3], line 72\u001b[0m, in \u001b[0;36mget_pbp\u001b[0;34m(date, team1, team2)\u001b[0m\n\u001b[1;32m     70\u001b[0m date \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(date)\n\u001b[1;32m     71\u001b[0m suffix \u001b[38;5;241m=\u001b[39m get_game_suffix(date, team1, team2)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/boxscores\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 72\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mget_pbp_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     74\u001b[0m df \u001b[38;5;241m=\u001b[39m format_df(df)\n",
      "Cell \u001b[0;32mIn[3], line 36\u001b[0m, in \u001b[0;36mget_pbp_helper\u001b[0;34m(suffix)\u001b[0m\n\u001b[1;32m     34\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(r\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     35\u001b[0m table \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m'\u001b[39m, attrs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpbp\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_html\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflavor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlxml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/sandbox/lib/python3.10/site-packages/pandas/io/html.py:1212\u001b[0m, in \u001b[0;36mread_html\u001b[0;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links, dtype_backend)\u001b[0m\n\u001b[1;32m   1208\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[1;32m   1210\u001b[0m io \u001b[38;5;241m=\u001b[39m stringify_path(io)\n\u001b[0;32m-> 1212\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflavor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflavor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthousands\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mna_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisplayed_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplayed_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextract_links\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1230\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/sandbox/lib/python3.10/site-packages/pandas/io/html.py:977\u001b[0m, in \u001b[0;36m_parse\u001b[0;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m retained \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m flav \u001b[38;5;129;01min\u001b[39;00m flavor:\n\u001b[0;32m--> 977\u001b[0m     parser \u001b[38;5;241m=\u001b[39m \u001b[43m_parser_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflav\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    978\u001b[0m     p \u001b[38;5;241m=\u001b[39m parser(io, compiled_match, attrs, encoding, displayed_only, extract_links)\n\u001b[1;32m    980\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/sandbox/lib/python3.10/site-packages/pandas/io/html.py:934\u001b[0m, in \u001b[0;36m_parser_dispatch\u001b[0;34m(flavor)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _HAS_LXML:\n\u001b[0;32m--> 934\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlxml not found, please install it\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _valid_parsers[flavor]\n",
      "\u001b[0;31mImportError\u001b[0m: lxml not found, please install it"
     ]
    }
   ],
   "source": [
    "nba_wt_results_yesterday = pd.DataFrame()\n",
    "\n",
    "# extract new results\n",
    "for game_number in range(len(nba_schedule_df_retro)):\n",
    "    if (game_number % 9) == 0:\n",
    "        sleep(120)\n",
    "    date = nba_schedule_df_retro.loc[game_number, \"DATE\"]\n",
    "    away_team = nba_schedule_df_retro.loc[game_number, \"AWAY_TEAM\"]\n",
    "    home_team = nba_schedule_df_retro.loc[game_number, \"HOME_TEAM\"]\n",
    "    pbp_df = get_pbp(date, away_team, home_team)\n",
    "    # print(str(date) + '-' + str(game_number) + '-' + away_team + '-' + home_team)\n",
    "    wp_results = calculate_game_wp(pbp_df, date, away_team, home_team)\n",
    "    nba_wt_results_yesterday = pd.concat([nba_wt_results_yesterday, wp_results]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c42103d-7add-4541-bef9-c432fb82c6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_wt_results_yesterday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b9854a-bd35-4573-8c59-93cfce787985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat into one df\n",
    "# nba_wt_results_df = pd.concat([nba_wt_results_df, nba_wt_results_yesterday])\n",
    "# nba_wt_results_df.to_csv('24_25_catchup/24_25_wt_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19316061-3544-46a3-b79b-486a54a1bd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conduct aggregations\n",
    "# calculate 2022-23 LT% and TIE%\n",
    "nba_wt_results_df['AWAY_LT'] = nba_wt_results_df['HOME_WT']\n",
    "nba_wt_results_df['HOME_LT'] = nba_wt_results_df['AWAY_WT']\n",
    "nba_wt_results_df['HOME_LT'] = nba_wt_results_df['AWAY_WT']\n",
    "nba_wt_results_df['TIE_PC'] = 1 - (nba_wt_results_df['AWAY_WT'] + nba_wt_results_df['HOME_WT'])\n",
    "\n",
    "# create datatset of wt/lt/tie%\n",
    "wt_results = calculate_tm_avg_metric(nba_wt_results_df, 'WT')\n",
    "lt_results = calculate_tm_avg_metric(nba_wt_results_df, 'LT')\n",
    "tie_results = calculate_tm_avg_metric(nba_wt_results_df, 'TIE_PC')\n",
    "\n",
    "del wt_results['DATE']\n",
    "del lt_results['DATE']\n",
    "del tie_results['DATE']\t\n",
    "\n",
    "nba_results_agg = pd.merge(wt_results, lt_results, how='inner', on='TEAM')\n",
    "nba_results_agg = pd.merge(nba_results_agg, tie_results, how='inner', on='TEAM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e356685-48d2-418b-8d8a-6dc838e71ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional validation that data is accurate\n",
    "print((nba_results_22_23_agg['WT'] + nba_results_22_23_agg['LT'] + nba_results_22_23_agg['TIE_PC']).min())\n",
    "print((nba_results_22_23_agg['WT'] + nba_results_22_23_agg['LT'] + nba_results_22_23_agg['TIE_PC']).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f97d9b-cbcd-4e4c-80e6-808c5e5a07d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## things to extract (from cleaningtheglass)\n",
    "# WP (wins/loss), #PT_DIFF, #Expected_WIN\n",
    "html = urlopen('https://cleaningtheglass.com/stats/league/summary')\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "table = soup.find(\"table\")\n",
    "df_ctg = pd.read_html(str(table), flavor='lxml')[0]\n",
    "df_ctg.columns = df_ctg.columns.get_level_values(1)\n",
    "df_ctg = df_ctg.iloc[: , 1:]\n",
    "df_ctg = df_ctg.iloc[: , :7]\n",
    "df_ctg_1 = df_ctg['Team']\n",
    "df_ctg_2 = df_ctg.iloc[: , 2:5]\n",
    "df_ctg_3 = df_ctg.iloc[: , 5:]\n",
    "df_ctg = pd.concat([df_ctg_1, df_ctg_2, df_ctg_3], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbfd3e1-c2b8-4604-b67d-dce64d80329a",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_names = {\n",
    "\t\t'full_name':[\n",
    "\t\t\t'Atlanta',\n",
    "\t\t\t'Boston',\n",
    "\t\t\t'Brooklyn',\n",
    "\t\t\t'Charlotte',\n",
    "\t\t\t'Chicago',\n",
    "\t\t\t'Cleveland',\n",
    "\t\t\t'Dallas',\n",
    "\t\t\t'Denver',\n",
    "\t\t\t'Detroit',\n",
    "\t\t\t'Golden State',\n",
    "\t\t\t'Houston',\n",
    "\t\t\t'Indiana',\n",
    "\t\t\t'LA Clippers',\n",
    "\t\t\t'LA Lakers',\n",
    "\t\t\t'Memphis',\n",
    "\t\t\t'Miami',\n",
    "\t\t\t'Milwaukee',\n",
    "\t\t\t'Minnesota',\n",
    "\t\t\t'New Orleans',\n",
    "\t\t\t'New York',\n",
    "\t\t\t'Oklahoma City',\n",
    "\t\t\t'Orlando',\n",
    "\t\t\t'Philadelphia',\n",
    "\t\t\t'Phoenix',\n",
    "\t\t\t'Portland',\n",
    "\t\t\t'Sacramento',\n",
    "\t\t\t'San Antonio',\n",
    "\t\t\t'Toronto',\n",
    "\t\t\t'Utah',\n",
    "\t\t\t'Washington'\n",
    "\t\t\t],\n",
    "\t\t'abbr_name':[\n",
    "\t\t\t'ATL',\n",
    "\t\t\t'BOS',\n",
    "\t\t\t'BRK',\n",
    "\t\t\t'CHO',\n",
    "\t\t\t'CHI',\n",
    "\t\t\t'CLE',\n",
    "\t\t\t'DAL',\n",
    "\t\t\t'DEN',\n",
    "\t\t\t'DET',\n",
    "\t\t\t'GSW',\n",
    "\t\t\t'HOU',\n",
    "\t\t\t'IND',\n",
    "\t\t\t'LAC',\n",
    "\t\t\t'LAL',\n",
    "\t\t\t'MEM',\n",
    "\t\t\t'MIA',\n",
    "\t\t\t'MIL',\n",
    "\t\t\t'MIN',\n",
    "\t\t\t'NOP',\n",
    "\t\t\t'NYK',\n",
    "\t\t\t'OKC',\n",
    "\t\t\t'ORL',\n",
    "\t\t\t'PHI',\n",
    "\t\t\t'PHO',\n",
    "\t\t\t'POR',\n",
    "\t\t\t'SAC',\n",
    "\t\t\t'SAS',\n",
    "\t\t\t'TOR',\n",
    "\t\t\t'UTA',\n",
    "\t\t\t'WAS'\n",
    "\t\t\t]\n",
    "\t}\n",
    "\n",
    "\tteam_name_map = pd.DataFrame(team_names)\n",
    "\n",
    "\tdf_ctg = pd.merge(df_ctg, team_name_map, how='inner', left_on ='Team', right_on='full_name')\n",
    "\tdel df_ctg['Team']\n",
    "\tdel df_ctg['full_name']\n",
    "\tdf_ctg = df_ctg.rename(columns={\n",
    "\t\t'abbr_name':'TEAM',\n",
    "\t\t'Win%':'WP',\n",
    "\t\t'Exp W82':'EXPECTED_WIN',\n",
    "\t\t'Point Diff':'PT_DIFF',\n",
    "\t\t'W':'Wins',\n",
    "\t\t'L':'Losses'\n",
    "\t})\n",
    "\n",
    "\tdf_ctg['WP'] = df_ctg['WP'].str.rstrip('%').astype('float') / 100.0\n",
    "\tdf_ctg['EXPECTED_WP'] = df_ctg['EXPECTED_WIN'] / 82\n",
    "\n",
    "\n",
    "\tnba_wt_results_agg = pd.merge(nba_results_agg, df_ctg, how='inner', on='TEAM')\n",
    "\tnba_wt_results_agg['WT_v_WP'] = nba_wt_results_agg['WT'] - nba_wt_results_agg['WP']\n",
    "\tnba_wt_results_agg['WT_v_EXP_WP'] = nba_wt_results_agg['WT'] - nba_wt_results_agg['EXPECTED_WP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec09ccdb-d1d1-4d6e-a44c-53cd1fb1b64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_wt_results_agg.to_csv('wt_support/nba_wt_results_agg.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
